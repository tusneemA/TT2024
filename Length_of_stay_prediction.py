# -*- coding: utf-8 -*-
"""Pipeline 2: Length of Stay Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JoPpXqqB1_lGF1XscBOsDHMLtgvlOYI1
"""

!pip install pyhealth

"""### **Step 1: Load dataset**

"""

from pyhealth.datasets import MIMIC3Dataset

mimic3_ds = MIMIC3Dataset(
        root="https://storage.googleapis.com/pyhealth/Synthetic_MIMIC-III/",
        tables=["DIAGNOSES_ICD", "PROCEDURES_ICD", "PRESCRIPTIONS"],
        code_mapping={},
        dev=True,
)

mimic3_ds.stat()

# data format
mimic3_ds.info()

# mimic3_ds.patients
# mimic3_ds.patients['947']
# mimic3_ds.patients['947'].visits
# mimic3_ds.patients['947'].visits['100999']
# mimic3_ds.patients['947'].visits['100999'].get_code_list('DIAGNOSES_ICD')

from pyhealth.tasks import length_of_stay_prediction_mimic3_fn

task_mimic3_ds = mimic3_ds.set_task(task_fn=length_of_stay_prediction_mimic3_fn)
# stats info
task_mimic3_ds.stat()

# show a data sample
task_mimic3_ds.samples[0]

from pyhealth.datasets.splitter import split_by_patient
from pyhealth.datasets import split_by_patient, get_dataloader

# data split
train_dataset, val_dataset, test_dataset = split_by_patient(task_mimic3_ds, [0.8, 0.1, 0.1])

# create dataloaders (they are <torch.data.DataLoader> object)
train_loader = get_dataloader(train_dataset, batch_size=64, shuffle=True)
val_loader = get_dataloader(val_dataset, batch_size=64, shuffle=False)
test_loader = get_dataloader(test_dataset, batch_size=64, shuffle=False)

"""### **Step 3: Define ML Model**

"""

from pyhealth.models import Transformer

model = Transformer(
    dataset=task_mimic3_ds,
    # look up what are available for "feature_keys" and "label_keys" in dataset.samples[0]
    feature_keys=["conditions", "procedures"],
    label_key="label",
    mode="multiclass",
    num_layers=2,
)

"""### **Step 4: Model Training**
-
"""

from pyhealth.trainer import Trainer

trainer = Trainer(model=model, metrics=["accuracy", "jaccard_weighted"])

trainer.train(
    train_dataloader=train_loader,
    val_dataloader=val_loader,
    epochs=5,
    monitor="jaccard_weighted",
)

"""### **Step 5: Evaluation**"""

# option 1: use our built-in evaluation metric
score = trainer.evaluate(test_loader)
print (score)

# option 2: use our pyhealth.metrics to evaluate
from pyhealth.metrics.multiclass import multiclass_metrics_fn

y_true, y_prob, loss = trainer.inference(test_loader)
multiclass_metrics_fn(y_true, y_prob, metrics=["accuracy", "f1_macro", "f1_micro", "cohen_kappa"])

